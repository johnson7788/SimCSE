## SimCSE: Simple Contrastive Learning of Sentence Embeddings

This repository contains the code and pre-trained models for our paper [SimCSE: Simple Contrastive Learning of Sentence Embeddings](https://arxiv.org/abs/2104.08821).

**************************** **Updates** ****************************

<!-- Thanks for your interest in our repo! -->

<!-- Probably you will think this as another *"empty"* repo of a preprint paper ğŸ¥±.
Wait a minute! The authors are working day and night ğŸ’ª, to make the code and models available, so you can explore our state-of-the-art sentence embeddings.
We anticipate the code will be out * **in one week** *. -->

<!-- * 4/26: SimCSE is now on [Gradio Web Demo](https://gradio.app/g/AK391/SimCSE) (Thanks [@AK391](https://github.com/AK391)!). Try it out! -->
* 8/31: Our paper has been accepted to EMNLP! Please check out our [updated paper](https://arxiv.org/pdf/2104.08821.pdf) (with updated numbers and baselines). 
* 5/12: We updated our [unsupervised models](#model-list) with new hyperparameters and better performance.
* 5/10: We released our [sentence embedding tool](#getting-started) and [demo code](./demo).
* 4/23: We released our [training code](#training).
* 4/20: We released our [model checkpoints](#use-our-models-out-of-the-box) and [evaluation code](#evaluation).
* 4/18: We released [our paper](https://arxiv.org/pdf/2104.08821.pdf). Check it out!


## Quick Links

  - [Overview](#overview)
  - [Getting Started](#getting-started)
  - [Model List](#model-list)
  - [Use SimCSE with Huggingface](#use-simcse-with-huggingface)
  - [Train SimCSE](#train-simcse)
    - [Requirements](#requirements)
    - [Evaluation](#evaluation)
    - [Training](#training)
  - [Bugs or Questions?](#bugs-or-questions)
  - [Citation](#citation)
  - [SimCSE Elsewhere](#simcse-elsewhere)

## Overview
æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç®€å•çš„å¯¹æ¯”æ€§å­¦ä¹ æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åŒæ—¶é€‚ç”¨äºæ— æ ‡ç­¾å’Œæœ‰æ ‡ç­¾çš„æ•°æ®ã€‚æ— ç›‘ç£çš„SimCSEåªéœ€è¦ä¸€ä¸ªè¾“å…¥å¥å­ï¼Œå¹¶åœ¨ä¸€ä¸ªå¯¹æ¯”å­¦ä¹ æ¡†æ¶ä¸­é¢„æµ‹è‡ªå·±ï¼Œåªç”¨æ ‡å‡†çš„dropoutä½œä¸ºå™ªéŸ³ã€‚æˆ‘ä»¬çš„æœ‰ç›‘ç£çš„SimCSEé€šè¿‡ä½¿ç”¨ "entailment "å¯¹ä½œä¸ºæ­£ä¾‹ï¼Œ"contradiction "å¯¹ä½œä¸ºå›°éš¾æ€§è´Ÿæ ·æœ¬ï¼Œå°†æ¥è‡ªNLIæ•°æ®é›†çš„æ ‡æ³¨å¯¹çº³å…¥å¯¹æ¯”å­¦ä¹ ã€‚ä¸‹å›¾æ˜¯æˆ‘ä»¬æ¨¡å‹çš„è¯´æ˜ã€‚

![](figure/model.png)

## Getting Started
æˆ‘ä»¬åœ¨SimCSEæ¨¡å‹çš„åŸºç¡€ä¸Šæä¾›äº†ä¸€ä¸ªæ˜“äºä½¿ç”¨çš„å¥å­åµŒå…¥å·¥å…·ï¼ˆè¯¦ç»†ç”¨æ³•è§æˆ‘ä»¬çš„[Wiki]ï¼ˆhttps://gi thub.com/princeton-nlp/SimCSE/wikiï¼‰ï¼‰ã€‚è¦ä½¿ç”¨è¯¥å·¥å…·ï¼Œé¦–å…ˆè¦ä»PyPIå®‰è£…`simcse`åŒ…
```bash
pip install simcse
```

Or directly install it from our code
```bash
python setup.py install
```
è¯·æ³¨æ„ï¼Œå¦‚æœæ‚¨æƒ³å¯ç”¨GPUç¼–ç ï¼Œæ‚¨åº”è¯¥å®‰è£…æ”¯æŒCUDAçš„æ­£ç¡®ç‰ˆæœ¬çš„PyTorchã€‚è¯·å‚é˜…[PyTorchå®˜æ–¹ç½‘ç«™](https://pytorch.org)äº†è§£ç›¸å…³è¯´æ˜ã€‚
å®‰è£…å®Œè½¯ä»¶åŒ…åï¼Œä½ å¯ä»¥é€šè¿‡ä¸¤è¡Œä»£ç åŠ è½½æˆ‘ä»¬çš„æ¨¡å‹
```python
from simcse import SimCSE
model = SimCSE("princeton-nlp/sup-simcse-bert-base-uncased")
```
See [model list](#model-list) for a full list of available models. 
ç„¶åä½ å¯ä»¥ä½¿ç”¨æˆ‘ä»¬çš„æ¨¡å‹æ¥**å°†å¥å­ç¼–ç ä¸ºåµŒå…¥**ã€‚
```python
embeddings = model.encode("A woman is reading.")
```

**è®¡ç®—ä¸¤ç»„å¥å­ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦**ã€‚
```python
sentences_a = ['A woman is reading.', 'A man is playing a guitar.']
sentences_b = ['He plays guitar.', 'A woman is making a photo.']
similarities = model.similarity(sentences_a, sentences_b)
```

æˆ–è€…ä¸ºä¸€ç»„å¥å­å»ºç«‹ç´¢å¼•å¹¶åœ¨å…¶ä¸­**æœç´¢
```python
sentences = ['A woman is reading.', 'A man is playing a guitar.']
model.build_index(sentences)
results = model.search("He plays guitar.")
```

æˆ‘ä»¬ä¹Ÿæ”¯æŒ[faiss](https://gi thub.com/facebookresearch/faiss)ï¼Œä¸€ä¸ªé«˜æ•ˆçš„ç›¸ä¼¼åº¦æœç´¢åº“ã€‚åªè¦æŒ‰ç…§è¿™é‡Œçš„[è¯´æ˜](https://github.com/princeton-nlp/SimCSE/wiki/Installation)å®‰è£…è½¯ä»¶åŒ…ï¼Œ`simcse`å°†è‡ªåŠ¨ä½¿ç”¨`faiss`è¿›è¡Œé«˜æ•ˆæœç´¢ã€‚

**è­¦å‘Š**ã€‚æˆ‘ä»¬å‘ç°`faiss`ä¸èƒ½å¾ˆå¥½åœ°æ”¯æŒNvidia AMPERE GPUï¼ˆ3090å’ŒA100ï¼‰ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½ åº”è¯¥æ”¹ç”¨å…¶ä»–GPUæˆ–å®‰è£…CPUç‰ˆæœ¬çš„`faiss`åŒ…ã€‚
æˆ‘ä»¬è¿˜æä¾›äº†ä¸€ä¸ªæ˜“äºæ„å»ºçš„[æ¼”ç¤ºç½‘ç«™](./demo)æ¥å±•ç¤ºSimCSEå¦‚ä½•ç”¨äºå¥å­æ£€ç´¢ã€‚è¯¥ä»£ç åŸºäº[DensePhrases](https://arxiv.org/abs/2012.12624)' 
[repo](https://github.com/princeton-nlp/DensePhrases)å’Œ[demo](http://densephrases.korea.ac.kr)ï¼ˆéå¸¸æ„Ÿè°¢DensePhrasesçš„ä½œè€…ï¼‰ã€‚

## Model List
æˆ‘ä»¬å·²ç»å‘å¸ƒçš„æ¨¡å‹åˆ—ä¸¾å¦‚ä¸‹ã€‚ä½ å¯ä»¥é€šè¿‡ä½¿ç”¨`simcse`åŒ…æˆ–ä½¿ç”¨[HuggingFace's Transformers]ï¼ˆhttps://github.com/huggingface/transformersï¼‰å¯¼å…¥è¿™äº›æ¨¡å‹ã€‚

|              Model              | Avg. STS |
|:-------------------------------|:--------:|
|  [princeton-nlp/unsup-simcse-bert-base-uncased](https://huggingface.co/princeton-nlp/unsup-simcse-bert-base-uncased) |   76.25 |
| [princeton-nlp/unsup-simcse-bert-large-uncased](https://huggingface.co/princeton-nlp/unsup-simcse-bert-large-uncased) |   78.41  |
|    [princeton-nlp/unsup-simcse-roberta-base](https://huggingface.co/princeton-nlp/unsup-simcse-roberta-base)    |   76.57  |
|    [princeton-nlp/unsup-simcse-roberta-large](https://huggingface.co/princeton-nlp/unsup-simcse-roberta-large)   |   78.90  |
|   [princeton-nlp/sup-simcse-bert-base-uncased](https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased)  |   81.57  |
|  [princeton-nlp/sup-simcse-bert-large-uncased](https://huggingface.co/princeton-nlp/sup-simcse-bert-large-uncased)  |   82.21  |
|     [princeton-nlp/sup-simcse-roberta-base](https://huggingface.co/princeton-nlp/sup-simcse-roberta-base)     |   82.52  |
|     [princeton-nlp/sup-simcse-roberta-large](https://huggingface.co/princeton-nlp/sup-simcse-roberta-large)    |   83.76  |

è¯·æ³¨æ„ï¼Œåœ¨é‡‡ç”¨äº†ä¸€ç»„æ–°çš„è¶…å‚æ•°ï¼ˆå…³äºè¶…å‚æ•°ï¼Œè§[è®­ç»ƒ](#è®­ç»ƒ)éƒ¨åˆ†ï¼‰åï¼Œç»“æœæ¯”æˆ‘ä»¬åœ¨å½“å‰ç‰ˆæœ¬çš„è®ºæ–‡ä¸­æŠ¥å‘Šçš„è¦å¥½ä¸€ç‚¹ã€‚
**å‘½åè§„åˆ™**ã€‚`unsup`å’Œ`sup`åˆ†åˆ«ä»£è¡¨ "æ— ç›‘ç£"ï¼ˆåœ¨ç»´åŸºç™¾ç§‘è¯­æ–™åº“ä¸Šè®­ç»ƒï¼‰å’Œ "æœ‰ç›‘ç£"ï¼ˆåœ¨NLIæ•°æ®é›†ä¸­è®­ç»ƒï¼‰ã€‚

## Use SimCSE with Huggingface
é™¤äº†ä½¿ç”¨æˆ‘ä»¬æä¾›çš„å¥å­åµŒå…¥å·¥å…·ï¼Œä½ ä¹Ÿå¯ä»¥ç”¨HuggingFaceçš„ "transformer "è½»æ¾å¯¼å…¥æˆ‘ä»¬çš„æ¨¡å‹ã€‚

```python
import torch
from scipy.spatial.distance import cosine
from transformers import AutoModel, AutoTokenizer

# Import our models. The package will take care of downloading the models automatically
tokenizer = AutoTokenizer.from_pretrained("princeton-nlp/sup-simcse-bert-base-uncased")
model = AutoModel.from_pretrained("princeton-nlp/sup-simcse-bert-base-uncased")

# Tokenize input texts
texts = [
    "There's a kid on a skateboard.",
    "A kid is skateboarding.",
    "A kid is inside the house."
]
inputs = tokenizer(texts, padding=True, truncation=True, return_tensors="pt")

# Get the embeddings
with torch.no_grad():
    embeddings = model(**inputs, output_hidden_states=True, return_dict=True).pooler_output

# Calculate cosine similarities
# Cosine similarities are in [-1, 1]. Higher means more similar
cosine_sim_0_1 = 1 - cosine(embeddings[0], embeddings[1])
cosine_sim_0_2 = 1 - cosine(embeddings[0], embeddings[2])

print("Cosine similarity between \"%s\" and \"%s\" is: %.3f" % (texts[0], texts[1], cosine_sim_0_1))
print("Cosine similarity between \"%s\" and \"%s\" is: %.3f" % (texts[0], texts[2], cosine_sim_0_2))
```

å¦‚æœä½ åœ¨é€šè¿‡HuggingFaceçš„APIç›´æ¥åŠ è½½æ¨¡å‹æ—¶é‡åˆ°ä»»ä½•é—®é¢˜ï¼Œä½ ä¹Ÿå¯ä»¥ä»ä¸Šè¡¨æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨`model = AutoModel.from_pretrained({PATH TO THE DOWNLOAD MODEL})`ã€‚

## Train SimCSE
åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æè¿°å¦‚ä½•é€šè¿‡ä½¿ç”¨æˆ‘ä»¬çš„ä»£ç æ¥è®­ç»ƒä¸€ä¸ªSimCSEæ¨¡å‹ã€‚

### Requirements
é¦–å…ˆï¼ŒæŒ‰ç…§[å®˜æ–¹ç½‘ç«™](https://pytorch.org)çš„è¯´æ˜å®‰è£…PyTorchã€‚ä¸ºäº†å¿ å®åœ°å†ç°æˆ‘ä»¬çš„ç»“æœï¼Œ
è¯·ä½¿ç”¨ä¸æ‚¨çš„å¹³å°/CUDAç‰ˆæœ¬ç›¸å¯¹åº”çš„æ­£ç¡®çš„`1.7.1`ç‰ˆæœ¬ã€‚é«˜äº`1.7.1`çš„PyTorchç‰ˆæœ¬ä¹Ÿåº”è¯¥å¯ä»¥å·¥ä½œã€‚
ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨ä½¿ç”¨Linuxå’Œ**CUDA11**ï¼ˆ[å¦‚ä½•æ£€æŸ¥CUDAç‰ˆæœ¬](https://varhowto.com/check-cuda-version/)ï¼‰ï¼Œè¯·é€šè¿‡ä»¥ä¸‹å‘½ä»¤å®‰è£…PyTorchã€‚

```bash
pip install torch==1.7.1+cu110 -f https://download.pytorch.org/whl/torch_stable.html
```

å¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯**CUDA**`<11`æˆ–**CPU**ï¼Œè¯·é€šè¿‡ä»¥ä¸‹å‘½ä»¤å®‰è£…PyTorchã€‚

```bash
pip install torch==1.7.1
```


ç„¶åè¿è¡Œä¸‹é¢çš„è„šæœ¬æ¥å®‰è£…å…¶ä½™çš„ä¾èµ–é¡¹ã€‚

```bash
pip install -r requirements.txt
```

### Evaluation
æˆ‘ä»¬å¯¹å¥å­åµŒå…¥çš„è¯„ä¼°ä»£ç æ˜¯åŸºäº[SentEval](https://github.com/facebookresearch/SentEval)çš„ä¿®æ”¹ç‰ˆã€‚
å®ƒåœ¨è¯­ä¹‰æ–‡æœ¬ç›¸ä¼¼æ€§ï¼ˆSTSï¼‰ä»»åŠ¡å’Œä¸‹æ¸¸è¿ç§»ä»»åŠ¡ä¸­å¯¹å¥å­åµŒå…¥è¿›è¡Œè¯„ä¼°ã€‚å¯¹äºSTSä»»åŠ¡ï¼Œæˆ‘ä»¬çš„è¯„ä¼°é‡‡ç”¨ "å…¨éƒ¨ "è®¾ç½®ï¼Œå¹¶æŠ¥å‘ŠSpearmançš„ç›¸å…³åº¦ã€‚è¯„ä¼°ç»†èŠ‚è§[æˆ‘ä»¬çš„è®ºæ–‡](https://arxiv.org/pdf/2104.08821.pdf)ï¼ˆé™„å½•Bï¼‰ã€‚

åœ¨è¯„ä¼°ä¹‹å‰ï¼Œè¯·é€šè¿‡è¿è¡Œä»¥ä¸‹ç¨‹åºä¸‹è½½è¯„ä¼°æ•°æ®é›†
```bash
cd SentEval/data/downstream/
bash download_dataset.sh
```
ç„¶åå›åˆ°æ ¹ç›®å½•ï¼Œä½ å¯ä»¥ä½¿ç”¨æˆ‘ä»¬çš„è¯„ä¼°ä»£ç è¯„ä¼°ä»»ä½•åŸºäº`transformers`çš„é¢„è®­ç»ƒæ¨¡å‹ã€‚æ¯”å¦‚è¯´ã€‚

```bash
python evaluation.py \
    --model_name_or_path princeton-nlp/sup-simcse-bert-base-uncased \
    --pooler cls \
    --task_set sts \
    --mode test
```
é¢„è®¡å®ƒå°†ä»¥è¡¨æ ¼çš„å½¢å¼è¾“å‡ºç»“æœã€‚

```
------ test ------
+-------+-------+-------+-------+-------+--------------+-----------------+-------+
| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |
+-------+-------+-------+-------+-------+--------------+-----------------+-------+
| 75.30 | 84.67 | 80.19 | 85.40 | 80.82 |    84.26     |      80.39      | 81.58 |
+-------+-------+-------+-------+-------+--------------+-----------------+-------+
```
è¯„ä¼°è„šæœ¬çš„å‚æ•°å¦‚ä¸‹ã€‚

* `--model_name_or_path`: åŸºäº "transformer "çš„é¢„è®­ç»ƒcheckpointçš„åç§°æˆ–è·¯å¾„ã€‚ä½ å¯ä»¥ç›´æ¥ä½¿ç”¨ä¸Šè¡¨ä¸­çš„æ¨¡å‹, e.g., `princeton-nlp/sup-simcse-bert-base-uncased`.
* `--pooler`: æ± åŒ–æ–¹æ³•ã€‚ç°åœ¨æˆ‘ä»¬æ”¯æŒ
    * `cls` (default): ä½¿ç”¨`[CLS]`tokençš„è¡¨ç¤ºã€‚åœ¨è¡¨ç¤ºä¹‹ååº”ç”¨ä¸€ä¸ªçº¿æ€§+æ¿€æ´»å±‚ï¼ˆå®ƒåœ¨æ ‡å‡†çš„BERTå®ç°ä¸­ï¼‰ã€‚å¦‚æœä½ ä½¿ç”¨**ç›‘ç£çš„SimCSE**ï¼Œä½ åº”è¯¥ä½¿ç”¨è¿™ä¸ªé€‰é¡¹ã€‚
    * `cls_before_pooler`: ä½¿ç”¨`[CLS]`tokençš„è¡¨ç¤ºæ³•ï¼Œæ²¡æœ‰é¢å¤–çš„çº¿æ€§+æ¿€æ´»ã€‚å¦‚æœä½ ä½¿ç”¨**æ— ç›‘ç£çš„SimCSE**ï¼Œä½ åº”è¯¥é‡‡å–è¿™ä¸ªé€‰é¡¹ã€‚
    * `avg`: æœ€åä¸€å±‚çš„å¹³å‡åµŒå…¥å€¼ã€‚å¦‚æœä½ ä½¿ç”¨SBERT/RoBERTaçš„checkpointï¼ˆ[è®ºæ–‡](https://arxiv.org/abs/1908.10084)ï¼‰ï¼Œä½ åº”è¯¥ä½¿ç”¨è¿™ä¸ªé€‰é¡¹ã€‚
    * `avg_top2`: æœ€åä¸¤å±‚çš„å¹³å‡åµŒå…¥é‡ã€‚
    * `avg_first_last`: ç¬¬ä¸€å±‚å’Œæœ€åä¸€å±‚çš„å¹³å‡åµŒå…¥å€¼ã€‚å¦‚æœä½ ä½¿ç”¨vanilla BERTæˆ–RoBERTaï¼Œè¿™ä¸ªæ•ˆæœæœ€å¥½ã€‚
* `--mode`: è¯„ä¼°æ¨¡å¼
    * `test` (é»˜è®¤)ã€‚é»˜è®¤çš„æµ‹è¯•æ¨¡å¼ã€‚ä¸ºäº†å¿ å®åœ°å†ç°æˆ‘ä»¬çš„ç»“æœï¼Œä½ åº”è¯¥ä½¿ç”¨è¿™ä¸ªé€‰é¡¹ã€‚
    * `dev`: æŠ¥å‘Šå¼€å‘é›†çš„ç»“æœã€‚æ³¨æ„ï¼Œåœ¨STSä»»åŠ¡ä¸­ï¼Œåªæœ‰`STS-B`å’Œ`SICK-R`æœ‰å¼€å‘é›†ï¼Œæ‰€ä»¥æˆ‘ä»¬åªæŠ¥å‘Šå®ƒä»¬çš„æ•°å­—ã€‚å®ƒè¿˜é‡‡å–å¿«é€Ÿæ¨¡å¼è¿›è¡Œè¿ç§»ä»»åŠ¡ï¼Œæ‰€ä»¥è¿è¡Œæ—¶é—´æ¯”`æµ‹è¯•`æ¨¡å¼çŸ­å¾—å¤šï¼ˆå°½ç®¡æ•°å­—ç•¥ä½ï¼‰ã€‚
    * `fasttest`: å®ƒä¸`test`ç›¸åŒï¼Œä½†æœ‰ä¸€ä¸ªå¿«é€Ÿæ¨¡å¼ï¼Œæ‰€ä»¥è¿è¡Œæ—¶é—´æ›´çŸ­ï¼Œä½†æŠ¥å‘Šçš„æ•°å­—å¯èƒ½æ›´ä½ï¼ˆåªé’ˆå¯¹è¿ç§»ä»»åŠ¡ï¼‰ã€‚
* `--task_set`: å¯¹å“ªä¸€ç»„ä»»åŠ¡è¿›è¡Œè¯„ä¼°ï¼ˆå¦‚æœè®¾ç½®ï¼Œå®ƒå°†è¦†ç›–`--tasks`ï¼‰ã€‚
    * `sts` (é»˜è®¤): åœ¨STSä»»åŠ¡ä¸Šè¿›è¡Œè¯„ä¼°ï¼ŒåŒ…æ‹¬`STS 12~16`ã€`STS-B`å’Œ`SICK-R`ã€‚è¿™æ˜¯è¯„ä¼°å¥å­åµŒå…¥è´¨é‡çš„æœ€å¸¸ç”¨çš„ä»»åŠ¡é›†ã€‚
    * `transfer`: å¯¹è¿ç§»ä»»åŠ¡è¿›è¡Œè¯„ä¼°ã€‚
    * `full`: å¯¹STSå’Œè¿ç§»ä»»åŠ¡è¿›è¡Œè¯„ä¼°ã€‚
    * `na`: é€šè¿‡`--tasks`æ‰‹åŠ¨è®¾ç½®ä»»åŠ¡ã€‚
* `--tasks`: æŒ‡å®šè¦è¯„ä¼°çš„æ•°æ®é›†ã€‚å¦‚æœ`--task_set`ä¸æ˜¯`na`ï¼Œå°†è¢«é‡å†™ã€‚å®Œæ•´çš„ä»»åŠ¡åˆ—è¡¨è§ä»£ç ã€‚

### Training

**Data**
å¯¹äºæ— ç›‘ç£çš„SimCSEï¼Œæˆ‘ä»¬ä»è‹±è¯­ç»´åŸºç™¾ç§‘ä¸­æŠ½å–100ä¸‡ä¸ªå¥å­ï¼›å¯¹äºæœ‰ç›‘ç£çš„SimCSEï¼Œæˆ‘ä»¬ä½¿ç”¨SNLIå’ŒMNLIæ•°æ®é›†ã€‚ä½ å¯ä»¥è¿è¡Œ`data/download_wiki.sh`å’Œ`data/download_nli.sh`æ¥ä¸‹è½½è¿™ä¸¤ä¸ªæ•°æ®é›†ã€‚

**Training scripts**
æˆ‘ä»¬ä¸ºæ— ç›‘ç£å’Œæœ‰ç›‘ç£çš„SimCSEæä¾›è®­ç»ƒè„šæœ¬çš„ä¾‹å­ã€‚åœ¨`run_unsup_example.sh`ä¸­ï¼Œæˆ‘ä»¬ä¸ºæ— ç›‘ç£ç‰ˆæœ¬æä¾›äº†ä¸€ä¸ªå•GPUï¼ˆæˆ–CPUï¼‰çš„ä¾‹å­ï¼Œåœ¨`run_sup_example.sh`ä¸­ï¼Œæˆ‘ä»¬ä¸ºæœ‰ç›‘ç£ç‰ˆæœ¬æä¾›äº†ä¸€ä¸ª**å¤šGPUçš„ä¾‹å­ã€‚ä¸¤ä¸ªè„šæœ¬éƒ½è°ƒç”¨`train.py`è¿›è¡Œè®­ç»ƒã€‚æˆ‘ä»¬åœ¨ä¸‹é¢è§£é‡Šå‚æ•°ã€‚
* `--train_file`: è®­ç»ƒæ–‡ä»¶è·¯å¾„ã€‚æˆ‘ä»¬æ”¯æŒ "txt "æ–‡ä»¶ï¼ˆä¸€è¡Œä»£è¡¨ä¸€ä¸ªå¥å­ï¼‰å’Œ "csv "æ–‡ä»¶ï¼ˆ2æ ï¼šæ²¡æœ‰å›°éš¾è´Ÿæ ·æœ¬çš„é…å¯¹æ•°æ®ï¼›3æ ï¼šæœ‰ä¸€ä¸ªç›¸åº”çš„å›°éš¾è´Ÿæ ·æœ¬å®ä¾‹çš„é…å¯¹æ•°æ®ï¼‰ã€‚ä½ å¯ä»¥ä½¿ç”¨æˆ‘ä»¬æä¾›çš„ç»´åŸºç™¾ç§‘æˆ–NLIæ•°æ®ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ä½ è‡ªå·±çš„ç›¸åŒæ ¼å¼çš„æ•°æ®ã€‚
* `--model_name_or_path`: é¢„è®­ç»ƒå¥½çš„checkpointå¼€å§‹ä½¿ç”¨ã€‚ç›®å‰ï¼Œæˆ‘ä»¬æ”¯æŒBERT-baseçš„æ¨¡å‹ (`bert-base-uncased`, `bert-large-uncased`, etc.) and RoBERTa-based models (`RoBERTa-base`, `RoBERTa-large`, etc.).
* `--temp`: å¯¹æ¯”æ€§æŸå¤±çš„æ¸©åº¦ã€‚
* `--pooler_type`: Pooling method. It's the same as the `--pooler_type` in the [evaluation part](#evaluation).
* `--mlp_only_train`: æˆ‘ä»¬å‘ç°ï¼Œå¯¹äºæ— ç›‘ç£çš„SimCSEæ¥è¯´ï¼Œç”¨MLPå±‚è®­ç»ƒæ¨¡å‹ï¼Œä½†ä¸æµ‹è¯•æ¨¡å‹ï¼Œæ•ˆæœæ›´å¥½ã€‚åœ¨è®­ç»ƒæ— ç›‘ç£çš„SimCSEæ¨¡å‹æ—¶ï¼Œä½ åº”è¯¥ä½¿ç”¨è¿™ä¸ªå‚æ•°ã€‚
* `--hard_negative_weight`: å¦‚æœä½¿ç”¨å›°éš¾è´Ÿæ ·æœ¬ï¼ˆå³è®­ç»ƒæ–‡ä»¶ä¸­æœ‰3åˆ—ï¼‰ï¼Œè¿™å°±æ˜¯æƒé‡çš„å¯¹æ•°ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæƒé‡æ˜¯1ï¼Œé‚£ä¹ˆè¿™ä¸ªå‚æ•°åº”è¯¥è¢«è®¾ç½®ä¸º0ï¼ˆé»˜è®¤å€¼ï¼‰ã€‚
* `--do_mlm`: æ˜¯å¦ä½¿ç”¨MLMè¾…åŠ©ç›®æ ‡ã€‚å¦‚æœä¸ºçœŸã€‚
  * `--mlm_weight`: MLMç›®æ ‡çš„æƒé‡ã€‚
  * `--mlm_probability`: MLMç›®æ ‡çš„maskedç‡ã€‚
 
* æœ‰ç›‘ç£run_unsup_example.sh 
train.py --model_name_or_path bert-base-uncased --train_file data/nli_for_simcse.csv --output_dir result/my-sup-simcse-bert-base-uncased --num_train_epochs 3 --per_device_train_batch_size 128 --learning_rate 5e-5 --max_seq_length 32 --evaluation_strategy steps --metric_for_best_model stsb_spearman --load_best_model_at_end --eval_steps 125 --pooler_type cls --overwrite_output_dir --temp 0.05 --do_train --do_eval --fp16

æ‰€æœ‰å…¶ä»–å‚æ•°éƒ½æ˜¯æ ‡å‡†çš„Huggingfaceçš„`transformers'è®­ç»ƒå‚æ•°ã€‚
ä¸€äº›ç»å¸¸ä½¿ç”¨çš„å‚æ•°æ˜¯ã€‚`--output_dir`, `--learning_rate`, `--per_device_train_batch_size`ã€‚
åœ¨æˆ‘ä»¬çš„ä¾‹å­è„šæœ¬ä¸­ï¼Œæˆ‘ä»¬è¿˜è®¾ç½®äº†åœ¨STS-Bå¼€å‘é›†ä¸Šè¯„ä¼°æ¨¡å‹ï¼ˆéœ€è¦åœ¨[evaluation](#evaluation)éƒ¨åˆ†ä¹‹åä¸‹è½½æ•°æ®é›†ï¼‰å¹¶ä¿å­˜æœ€ä½³checkpointã€‚

å¯¹äºæœ¬æ–‡çš„ç»“æœï¼Œæˆ‘ä»¬ä½¿ç”¨Nvidia 3090 GPUå’ŒCUDA 11ã€‚ä½¿ç”¨ä¸åŒç±»å‹çš„è®¾å¤‡æˆ–ä¸åŒç‰ˆæœ¬çš„CUDA/å…¶ä»–è½¯ä»¶å¯èƒ½ä¼šå¯¼è‡´æ€§èƒ½ç•¥æœ‰ä¸åŒã€‚

**Hyperparameters**
æˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹è¶…å‚æ•°å™¨æ¥è®­ç»ƒSimCSEã€‚

|               | Unsup. BERT | Unsup. RoBERTa | Sup.      |
|:--------------|:-----------:|:--------------:|:---------:|
| Batch size    | 64          | 512            | 512       |
| Learning rate (base)  | 3e-5 | 1e-5 | 5e-5 |
| Learning rate (large) | 1e-5 | 3e-5 | 1e-5 |


**Convert models**
æˆ‘ä»¬ä¿å­˜çš„checkpointä¸Huggingfaceçš„é¢„è®­ç»ƒcheckpointç•¥æœ‰ä¸åŒã€‚è¿è¡Œ`python simcse_to_huggingface.py --path {PATH_TO_CHECKPOINT_FOLDER}`æ¥è½¬æ¢å®ƒã€‚
ä¹‹åï¼Œä½ å¯ä»¥é€šè¿‡æˆ‘ä»¬çš„[è¯„ä¼°](#evaluation)ä»£ç æ¥è¯„ä¼°å®ƒï¼Œæˆ–è€…ç›´æ¥ä½¿ç”¨å®ƒ[out of the box](#use-our-models-out-of-the-box)ã€‚

## Bugs or questions?

If you have any questions related to the code or the paper, feel free to email Tianyu (`tianyug@cs.princeton.edu`) and Xingcheng (`yxc18@mails.tsinghua.edu.cn`). If you encounter any problems when using the code, or want to report a bug, you can open an issue. Please try to specify the problem with details so we can help you better and quicker!

## Citation

Please cite our paper if you use SimCSE in your work:

```bibtex
@inproceedings{gao2021simcse,
   title={{SimCSE}: Simple Contrastive Learning of Sentence Embeddings},
   author={Gao, Tianyu and Yao, Xingcheng and Chen, Danqi},
   booktitle={Empirical Methods in Natural Language Processing (EMNLP)},
   year={2021}
}
```

## SimCSE Elsewhere

We thank the community's efforts for extending SimCSE!

- [Jianlin Su](https://github.com/bojone) has provided [a Chinese version of SimCSE](https://github.com/bojone/SimCSE).
- [AK391](https://github.com/AK391) integrated to [Huggingface Spaces](https://huggingface.co/spaces) with [Gradio](https://github.com/gradio-app/gradio). See demo: [![Hugging Face Spaces](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/spaces/akhaliq/SimCSE)
- [Nils Reimers](https://github.com/nreimers) has implemented a `sentence-transformers`-based [training code](https://colab.research.google.com/drive/1gAjXcI4uSxDE_IcvZdswFYVAo7XvPeoU?usp=sharing#scrollTo=UXUsikOc6oiB) for SimCSE.
